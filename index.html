<!DOCTYPE html>
<html>
<head>
  <title>Sparse inverse covariance estimation with the graphical lasso</title>
  <meta charset="utf-8">
  <meta name="description" content="Sparse inverse covariance estimation with the graphical lasso">
  <meta name="author" content="Keith Hughitt">
  <meta name="generator" content="slidify" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <link rel="stylesheet" href="libraries/frameworks/io2012/css/default.css" media="all" >
  <link rel="stylesheet" href="libraries/frameworks/io2012/phone.css" 
    media="only screen and (max-device-width: 480px)" >
  <link rel="stylesheet" href="libraries/frameworks/io2012/css/slidify.css" >
  <link rel="stylesheet" href="libraries/highlighters/highlight.js/css/tomorrow.css" />
  <base target="_blank"> <!-- This amazingness opens all links in a new tab. -->
  <script data-main="libraries/frameworks/io2012/js/slides" 
    src="libraries/frameworks/io2012/js/require-1.0.8.min.js">
  </script>
  
    <link rel="stylesheet" href = "assets/css/ribbons.css">

</head>
<body style="opacity: 0">
  <slides class="layout-widescreen">
    
    <!-- LOGO SLIDE -->
    <!-- END LOGO SLIDE -->
    

    <!-- TITLE SLIDE -->
    <!-- Should I move this to a Local Layout File? -->
    <slide class="title-slide segue nobackground">
      <hgroup class="auto-fadein">
        <h1>Sparse inverse covariance estimation with the graphical lasso</h1>
        <h2>Friedman, J., Hastie, T., Tibshirani, R.</h2>
        <p>Keith Hughitt<br/></p>
      </hgroup>
          </slide>

    <!-- SLIDES -->
      <slide class="segue dark" id="slide-1" style="background:;">
  <hgroup>
    
  </hgroup>
  <article>
    <!-- Custom Styles -->

<style type='text/css'>
    slides > slide {
        height: 800px;
        margin-top: -400px;
    }
    img {
        max-height: 560px;
        max-width: 964px;
    }
    slide a {border-bottom: none;}
    .references li { font-size: 18px; }
</style>

<h2>Graphical Models</h2>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-2" style="background:;">
  <hgroup>
    <h2>Graphical Models</h2>
  </hgroup>
  <article>
    <p>Graphical models provide a way to represent the conditional dependencies 
between a number of random variables. They provide a visual way of representing 
the joint distribution of the entire set of RVs.</p>

<p><span class='red'>Components:</span></p>

<ul>
<li>Vertices: random variables</li>
<li>Edges: condition dependencies between RVs</li>
</ul>

<p><span class='red'>Types:</span></p>

<ul>
<li>Directed: <code>Bayesian networks</code> (causal relationships)</li>
<li>Undirected: <code>Markov random fields</code> / <code>Markov networks</code></li>
</ul>

<p>See <a href="http://www-stat.stanford.edu/%7Etibs/ElemStatLearn/">The Elements of Statistical Learning (ESM)</a>
chapter 17 for an overview of undirected graphical models.</p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-3" style="background:;">
  <hgroup>
    <h2>Graphical Models</h2>
  </hgroup>
  <article>
    <p>Constructing graphical models from data:</p>

<ul>
<li><span class='blue2'>Model selection</span>: choosing the structure of the graph.</li>
<li><span class='blue2'>Learning</span>: Estimating edge weights from data.</li>
</ul>

<p><img src="figure/pgm_example.png" alt="plot of chunk pgm_example"> </p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-4" style="background:;">
  <hgroup>
    <h2>Undirected Graphical Models</h2>
  </hgroup>
  <article>
    <h3>Gaussian Graphical Models</h3>

<ul>
<li><p>Assume that the observations have a multivariate Gaussian distribution with
mean \(\mu\) and covariance matrix \(\Sigma\).</p></li>
<li><p>The <span class='blue'>inverse covariance matrix</span> 
\(\Theta = \Sigma^{-1}\) (aka concentration matrix or precision matrix) 
contains information about the <span class='blue'>partial covariances</span> 
between each pair of nodes conditioned on all other variables (ESL.)</p></li>
<li><p>If the $ij$th component of \(\Theta\) is zero, then variables \(i\) and \(j\) are
conditionally independent, given the other variables.</p></li>
</ul>

<h3>Covariance graphs</h3>

<ul>
<li>In covariance graphs or relevance networks, edges are present when the
<span class='blue'>covariance</span> is non-zero.</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-5" style="background:;">
  <hgroup>
    <h2>Sparse Graphical Models</h2>
  </hgroup>
  <article>
    <ul class = "build">
<li>In some cases, you expect that the underlying data should be sparse.</li>
<li>Want to only keep significant edges.</li>
<li>An \(L_1\) penalty on the estimation of \(\Sigma^{-1}\) can be used to induce 
sparseness.</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="segue dark" id="slide-6" style="background:;">
  <hgroup>
    <h2>Using the Lasso for Sparse Graphical Models</h2>
  </hgroup>
  <article>
    
  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-7" style="background:;">
  <hgroup>
    <h2>Meinshausen and BÃ¼hlmann (2006)</h2>
  </hgroup>
  <article>
    <ul class = "build">
<li>Which components of \(\Sigma^{-1}\) are non-zero?</li>
<li>Fit a lasso regression for each variable using all other variables as
predictors.</li>
<li>Considered nonzero if \(\Sigma^{-1}_{ij} \neq 0\) AND/OR 
\(\Sigma^{-1}_{ji} \neq 0\)</li>
<li>Shown asymptotically to find nonzero components</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-8" style="background:;">
  <hgroup>
    <h2>Exact solutions</h2>
  </hgroup>
  <article>
    <p>Other authors have suggested exact solutions:</p>

<ul>
<li>Yuan &amp; Lin (2007)</li>
<li>Banerjee et al. (2007)</li>
<li>Dahl et al. (2007)</li>
</ul>

<p><a href="http://en.wikipedia.org/wiki/Interior_point_method">Interior point optimization</a>
is used to determine an exact maximiation.</p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-9" style="background:;">
  <hgroup>
    <h2>Graphical Lasso</h2>
  </hgroup>
  <article>
    <ul>
<li>Exact solution based on coordinate descent approach in Banerjee et al. (2007)</li>
</ul>

<p><span class='red' style='font-weight: 700;'>Approach</span></p>

<ul class = "build">
<li>\(N\) observations, \(x_i, i=1,\ldots,N\) with dimension \(p\), mean \(\mu\) and 
covariance \(\Sigma\)</li>
<li>let \(\Theta = \Sigma^{-1}\) and let \(S\) be the <span class='blue'>empirical
covariance matrix</span>:
\[S = \frac{1}{N} \sum_{i=1}^N (x_i - \overline{x})(x_i - \overline{x})^T\]</li>
<li><span class='blue'>Goal:</span> Maximize the log-likelihood
\[\text{log det} \Theta - \text{tr}(S\Theta) - \rho\Vert \Theta \Vert_1\]
over non-negative definite matrices \(\Theta\).</li>
<li>Above expression is the &quot;Gaussian log-likelihood of the data, partially
maximized with respect to the mean parameter \(\mu\).</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="segue dark" id="slide-10" style="background:;">
  <hgroup>
    <h2>An interesting methods discussion...</h2>
  </hgroup>
  <article>
    
  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-11" style="background:;">
  <hgroup>
    <h2>Algorithm (Friedman et al. 2007):</h2>
  </hgroup>
  <article>
    <ol>
<li>Start with \(W = S + \rho I\). The diagonal of \(W\) remains unchanged in what
follows.</li>
<li>For each \(j = 1,2,\ldots p,1,2,\ldots p,\ldots,\) solve the lasso problem:
<span class='blue'>
\[ min_\beta \{ \frac{1}{2} \Vert W^{1/2}_{11} \beta - b\Vert^2 + \rho \Vert \beta \Vert_1 \}\]
</span>
where \(b = W^{-1/2}_{11} s_{12}\), which takes as input the inner products 
\(W_{11}\) and \(s_{12}\).  This gives a \(p -1\) vector solution \(\hat{\beta}\). 
Fill in the corresponding row and column \(W\) using \(w_{12} = W_{11} \hat{\beta}\).</li>
<li>Continue to convergence.</li>
</ol>

<p>In <code>glasso</code>, the procedure stops when the average absolute change in \(W\) is
less than \(t \cdot  \text{ave} |S^{-\text{diag}}|\) where \(S^{-\text{diag}}\) are
the off-diagonal elements of the empirical coveriance matrix \(S\) and \(t\) is
a fixed threshold, set by default at 0.001.</p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="segue dark" id="slide-12" style="background:;">
  <hgroup>
    <h2>An interesting algorithm discussion...</h2>
  </hgroup>
  <article>
    
  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-13" style="background:;">
  <hgroup>
    <h2>Performance</h2>
  </hgroup>
  <article>
    <ul>
<li>Simulated data for sparse and dense scenarios:</li>
<li><p><span class='blue'>Sparse</span></p>

<ul>
<li> \((\Sigma^{-1})_{ii} = 1\), </li>
<li>\((\Sigma^{-1})_{i,i-1} = (\Sigma^{-1})_{i-1,i} = 0.5\)</li>
<li>0 otherwise</li>
</ul></li>
<li><p><span class='blue'>Dense</span></p>

<ul>
<li>\((\Sigma^{-1})_{ii} = 2\),</li>
<li>\((\Sigma^{-1})_{ii'} = 1\) otherwise</li>
</ul></li>
<li><p>Compared performance to <code>COVSEL</code> method from Banerjee et al. (2007).</p></li>
<li><p><span class='red'>Result</span>: Graphical lasso is 30-4000 times faster than
COVSEL and 2-10 slower than the approximate method.</p></li>
<li><p>Even for dense problems, finishes in ~1min for p=1000 features. (Hard to tell
from graph how it will scale to many more features, however).</p></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-14" style="background:;">
  <hgroup>
    <h2>Performance</h2>
  </hgroup>
  <article>
    <p><img src="assets/img/F1.large.jpg" alt="Figure 1"></p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-15" style="background:;">
  <hgroup>
    <h2>Cell signalling network</h2>
  </hgroup>
  <article>
    <p>To demonstrate the usefulness of the graphical lasso on real-world problems,
the method is applied to cytometry data from Sach et al. (2003) </p>

<p><img src="assets/img/Sachs_F2.large.jpg" alt="Figure 2">
(Sachs 2003, fig 2)</p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-16" style="background:;">
  <hgroup>
    <h2>Cell signalling network</h2>
  </hgroup>
  <article>
    <p><img src="assets/img/Sachs_F1.large.jpg" alt="Figure 1"></p>

<p>(Sachs 2003, fig 1)</p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-17" style="background:;">
  <hgroup>
    <h2>Cell signalling network</h2>
  </hgroup>
  <article>
    <p>Figure 2: Original network derived in Sachs et al.</p>

<p><img src="assets/img/F2.large.jpg" alt="Figure 2"></p>

<ul>
<li>\(p\) = 11 proteins</li>
<li>\(n\) = 7466 cells</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-18" style="background:;">
  <hgroup>
    <h2>Cell signalling network</h2>
  </hgroup>
  <article>
    <p>Figure 3: Undirected graphs generated using graphical lasso with various settings for
the regularization parameter, \(\rho\). 
<img src="assets/img/F3.large.jpg" alt="Figure 3"></p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-19" style="background:;">
  <hgroup>
    <h2>Cell signalling network</h2>
  </hgroup>
  <article>
    <p>Figure 4: Profile of coefficients as the total \(L_1\) norm of the coefficient
vector increases and \(\rho\) decreases. (The density of network increases as 
\(L_1\) increases.)</p>

<p><img src="assets/img/F4.large.jpg" alt="Figure 4"></p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-20" style="background:;">
  <hgroup>
    <h2>Cell signalling network</h2>
  </hgroup>
  <article>
    <p>Figure 5: LHS - tenfold cross-validation. RHS - regression sum of squares of
the exact graphical lasso vs. Meinhausen-Buhlmann approximation.</p>

<p><img src="assets/img/F5.large.jpg" alt="Figure 5"></p>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="segue dark" id="slide-21" style="background:;">
  <hgroup>
    <h2>Summary</h2>
  </hgroup>
  <article>
    
  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-22" style="background:;">
  <hgroup>
    <h2>Summary</h2>
  </hgroup>
  <article>
    <ol>
<li>Friedmann et al. present a fast \(L_1\) penalized approach for inducing
sparsity in graphical models.</li>
<li>Builds on previous methods, starting with the blockwise coordinate descent
approach from Banerjee et al. (2007.)</li>
<li>Method arrives at at exact result and performs significantly faster
than previous methods.</li>
<li>Free implementation of the graphical lasso written in fortran and R is
available: <code>glasso</code>.</li>
</ol>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="references" id="slide-23" style="background:;">
  <hgroup>
    <h2>References</h2>
  </hgroup>
  <article>
    <ul>
<li>J. Friedman, T. Hastie, R. Tibshirani,   (2007) Sparse Inverse Covariance Estimation With The Graphical Lasso.  <em>Biostatistics</em>  <strong>9</strong>  432-441  <a href="http://dx.doi.org/10.1093/biostatistics/kxm045">10.1093/biostatistics/kxm045</a></li>
<li>Nicolai Meinshausen, Peter BÃ¼hlmann,   (2006) High-Dimensional Graphs And Variable Selection With The Lasso.  <em>The Annals of Statistics</em>  <strong>34</strong>  1436-1462  <a href="http://dx.doi.org/10.1214/009053606000000281">10.1214/009053606000000281</a></li>
<li>K. Sachs,   (2005) Causal Protein-Signaling Networks Derived From Multiparameter Single-Cell Data.  <em>Science</em>  <strong>308</strong>  523-529  <a href="http://dx.doi.org/10.1126/science.1105809">10.1126/science.1105809</a></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

      <slide class="" id="slide-24" style="background:;">
  <hgroup>
    <h2>System info</h2>
  </hgroup>
  <article>
    <pre><code class="r">sessionInfo()
</code></pre>

<pre><code>## R version 3.0.2 (2013-09-25)
## Platform: x86_64-unknown-linux-gnu (64-bit)
## 
## locale:
##  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
##  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
##  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
##  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
##  [9] LC_ADDRESS=C               LC_TELEPHONE=C            
## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] knitcitations_0.4-7 bibtex_0.3-6        knitr_1.5          
## [4] igraph_0.6.5-2      slidify_0.3.3       colorout_1.0-0     
## [7] vimcom_0.9-9        setwidth_1.0-3     
## 
## loaded via a namespace (and not attached):
##  [1] digest_0.6.3   evaluate_0.5.1 formatR_0.9    httr_0.2      
##  [5] markdown_0.6.3 RCurl_1.95-4.1 stringr_0.6.2  tools_3.0.2   
##  [9] whisker_0.3-2  XML_3.98-1.1   xtable_1.7-1   yaml_2.1.8
</code></pre>

<!-- Custom JavaScript -->

<script src="http://ajax.aspnetcdn.com/ajax/jQuery/jquery-1.7.min.js"></script>

<script type='text/javascript'>
$(function() {
    $("p:has(img)").addClass('centered');
});
</script>

  </article>
  <!-- Presenter Notes -->
</slide>

    <slide class="backdrop"></slide>
  </slides>

  <!--[if IE]>
    <script 
      src="http://ajax.googleapis.com/ajax/libs/chrome-frame/1/CFInstall.min.js">  
    </script>
    <script>CFInstall.check({mode: 'overlay'});</script>
  <![endif]-->
</body>
<!-- Grab CDN jQuery, fall back to local if offline -->
<script src="http://ajax.aspnetcdn.com/ajax/jQuery/jquery-1.7.min.js"></script>
<script>window.jQuery || document.write('<script src="libraries/widgets/quiz/js/jquery-1.7.min.js"><\/script>')</script>
<!-- Load Javascripts for Widgets -->
<!-- MathJax: Fall back to local if CDN offline but local image fonts are not supported (saves >100MB) -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<!-- <script src="https://c328740.ssl.cf1.rackcdn.com/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script> -->
<script>window.MathJax || document.write('<script type="text/x-mathjax-config">MathJax.Hub.Config({"HTML-CSS":{imageFont:null}});<\/script><script src="libraries/widgets/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"><\/script>')
</script>
<!-- LOAD HIGHLIGHTER JS FILES -->
<script src="libraries/highlighters/highlight.js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<!-- DONE LOADING HIGHLIGHTER JS FILES -->
</html>